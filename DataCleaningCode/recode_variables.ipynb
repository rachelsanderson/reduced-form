{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master file containing functions for recoding variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from streetaddress import StreetAddressFormatter, StreetAddressParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in dictionaries for recoding variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonDir = '../../Data for Tax Equity Project/JSONFiles/'\n",
    "\n",
    "recode_dict = {}\n",
    "for fileName in glob.glob(jsonDir + \"*.txt\"):\n",
    "    dict_name = fileName.split(jsonDir)[-1].split('.txt')[0]\n",
    "    with open(fileName) as outfile:\n",
    "        recode_dict[dict_name] = json.load(outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code that cleans proposed generator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Clean Data/proposed_gen_master_list_post08.csv')\n",
    "df['region'] = df['plant_state'].map(recode_dict['region_dict'])\n",
    "df['regulated'] = df['plant_state'].map(recode_dict['regulated_dict'])\n",
    "df['status_clean'] = df['status'].map (recode_dict['status_dict'])\n",
    "df['alt_status'] = df['status'].map(recode_dict['alt_status_dict'])\n",
    "df['period'] = pd.cut(df['year'], bins=[min(df['year']-1), 2011, 2016, max(df['year'])],\n",
    "      labels = ['2009-2011: Loan grant + ITC', \n",
    "                '2012-2016: ITC Round 1', \n",
    "                '2017-2023: ITC Round 2'])\n",
    "df.drop([x for x in df.columns if \"Unnamed\" in x],axis=1,inplace=True)\n",
    "df.to_csv('../Clean Data/proposed_gen_master_list_post08.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic function for recoding state/year variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(fileName, state_var,year_var):\n",
    "    df = pd.read_csv(fileName)\n",
    "    df['region'] = df[state_var].map(region_dict)\n",
    "    df['regulated'] = df[state_var].map(regulated_dict)\n",
    "    df['period'] = pd.cut(df[year_var], bins=[min(df[year_var]-1), 2011, 2016, max(df[year_var])],\n",
    "      labels = ['2009-2011: Loan grant + ITC', \n",
    "                '2012-2016: ITC Round 1', \n",
    "                '2017-2023: ITC Round 2'])\n",
    "    df.to_csv(fileName[-3])\n",
    "    out_name = fileName[:-4] + '_new.csv'\n",
    "    df.to_csv(out_name)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = '../../Tax Equity Code/STATA/capacity_clean.csv'\n",
    "clean_df(fileName, 'State Code', 'Year');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = '../../Data for Tax Equity Project/eia_data/eia8602018/merged.csv'\n",
    "clean_df(fileName, 'plant_state','operating_year');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for cleaning street addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address(df, address_var):\n",
    "    s=\"\"\n",
    "    addr_formatter = StreetAddressFormatter()\n",
    "    df['clean_address']= df[address_var].apply(lambda x: addr_formatter.abbrev_street_avenue_etc(x))\n",
    "    df['clean_address'] = df['clean_address'].apply(lambda x: s.join(x.lower().split(\"flo\")[:-1]) if \"flo\" in x.lower() else x.lower())\n",
    "#     df['clean_address'] = df['clean_address'].apply(lambda x: s.join(x.lower().split(\"suite\")[:-1]) if \"flo\" in x.lower() else x.lower())\n",
    "    df['clean_address'] = df['clean_address'].apply(lambda x: x.replace(\",\", \" \").replace(\".\",\"\").replace(\"  \", \" \"))\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachelanderson/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (16,39,43,77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fileName = '../../Data for Tax Equity Project/eia_data/eia8602018/merged_new.csv'\n",
    "fileOut = \"../../Data for Tax Equity Project/eia_data/eia8602018/merged_clean_address.csv\"\n",
    "gen = pd.read_csv(fileName)\n",
    "gen.drop([x for x in gen.columns if \"Unnamed\" in x], axis=1, inplace=True)\n",
    "clean_gen = clean_address(gen,'street_address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clean_gen.to_csv(fileOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for fixing utilities (linking llcs to parent companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of subsidiary companies for top solar utilities\n",
    "\n",
    "utility_subsidiaries = {\n",
    "    \"Southern California Edison Co\": 'Edison International',\n",
    "\n",
    "# southern power co    \n",
    "'Southern Power Co': 'Southern Company',\n",
    "'Mississippi Power Co': 'Southern Company',\n",
    "'Alabama Power Co': 'Southern Company',\n",
    "'Georgia Power Co': 'Southern Company',\n",
    "\n",
    "'Consolidated Edison Energy, Inc.': 'Consolidated Edison',\n",
    "'Consolidated Edison Co-NY Inc': 'Consolidated Edison',\n",
    "'Consolidated Edison Development Inc': 'Consolidated Edison',\n",
    "'Consolidated Edison Solutions Inc': 'Consolidated Edison',\n",
    "    \n",
    "'Dominion Energy South Carolina, Inc': 'Dominion Energy',\n",
    "'Dominion Renewable Energy': 'Dominion Energy',\n",
    "'Virginia Electric & Power Co': 'Dominion Energy',\n",
    "'Dominion Renewable Energy - Clipperton'  : 'Dominion Energy',\n",
    "'Dominion Renewable Energy - Fremont': 'Dominion Energy',\n",
    "    \n",
    "'Florida Power & Light Co': 'NextEra',\n",
    "'Bythe Solar II, LLC': 'NextEra', \n",
    "'Blythe Solar 110': 'NextEra',\n",
    "'McCoy Solar, LLC': 'NextEra',\n",
    "'Silver State Solar Power South, LLC': 'NextEra',\n",
    "'Stuttgart Solar, LLC': 'NextEra',\n",
    "'Marshall Solar Energy Project': 'NextEra',\n",
    "    \n",
    "'BHER Power Resources, Inc': 'Berkshire Hathaway',\n",
    "'BHE Renewables, LLC': 'Berkshire Hathaway',\n",
    "'Topaz Solar Farms LLC': 'Berkshire Hathaway',\n",
    "    \n",
    "'Imperial Valley Solar, LLC': '8me',\n",
    "    \n",
    "'D E Shaw & Co., LP': 'DE Shaw',\n",
    "'North Star Solar PV LLC': 'DE Shaw',\n",
    "'MS Solar 2, LLC': 'DE Shaw'\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jsonDir + 'parent_utility_dict.txt', 'w') as outFile:\n",
    "    json.dump(utility_subsidiaries, outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_parent_comp(df, utility_var, address_var, utility_dict):\n",
    "    #for d in utility_dicts:\n",
    "        \n",
    "    df['parent_utility']=df[utility_var].map(utility_dict)\n",
    "    \n",
    "    df['parent_utility']=df['parent_utility'].fillna(df[utility_var])\n",
    "    \n",
    "    # assign same address to common parent \n",
    "    df[df[address_var].str.contains('1414 harbour way')]['parent_utility'] = \"Solar Star\"\n",
    "    df[df[address_var].str.contains('700 universe')]['parent_utility'] = 'NextEra'\n",
    "    \n",
    "    \n",
    "    df['parent_utility'] = df['parent_utility'].apply(lambda x: \"Duke Energy\" if \"Duke Energy\" in x else x)\n",
    "    df['parent_utility'] = df['parent_utility'].apply(lambda x: \"NextEra\" if \"NextEra\" in x else x)\n",
    "    df['parent_utility'] = df['parent_utility'].apply(lambda x: \"NRG\" if \"NRG\" in x else x)\n",
    "    df['parent_utility'] = df['parent_utility'].apply(lambda x: \"Solar Star\" if \"Solar Star\" in x else x)\n",
    "    df['parent_utility'] = df['parent_utility'].apply(lambda x: \"NRG\" if \"Agua Caliente Solar\" in x else x)\n",
    "    df['parent_utility'] = df['parent_utility'].apply(lambda x: \"NextEra\" if \"Blythe Solar\" in x else x)\n",
    "    df['parent_utility'] = df['parent_utility'].apply(lambda x: \"8me\" if \"8me\" in x.lower() else x)\n",
    "    df['parent_utility'] = df['parent_utility'].apply(lambda x: \"Exelon\" if \"AV Solar\" in x else x)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachelanderson/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/rachelanderson/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "clean_gen = id_parent_comp(clean_gen,'utility_name', 'clean_address', recode_dict['parent_utility_dict'])\n",
    "# clean_gen.to_csv(fileOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AL': 0.0,\n",
       " 'AK': 1.0,\n",
       " 'AZ': 0.0,\n",
       " 'AR': 1.0,\n",
       " 'CA': 1.0,\n",
       " 'CO': 1.0,\n",
       " 'CT': 1.0,\n",
       " 'DE': 1.0,\n",
       " 'DC': 1.0,\n",
       " 'FL': 1.0,\n",
       " 'GA': 0.0,\n",
       " 'HI': 1.0,\n",
       " 'ID': 0.0,\n",
       " 'IL': 0.0,\n",
       " 'IN': 0.0,\n",
       " 'IA': 1.0,\n",
       " 'KS': 1.0,\n",
       " 'KY': 0.0,\n",
       " 'LA': 0.0,\n",
       " 'ME': 1.0,\n",
       " 'MD': 1.0,\n",
       " 'MA': 1.0,\n",
       " 'MI': 0.0,\n",
       " 'MN': 1.0,\n",
       " 'MS': 0.0,\n",
       " 'MO': 1.0,\n",
       " 'MT': 1.0,\n",
       " 'NE': 1.0,\n",
       " 'NV': 1.0,\n",
       " 'NH': 1.0,\n",
       " 'NJ': 1.0,\n",
       " 'NM': 0.0,\n",
       " 'NY': 0.0,\n",
       " 'NC': 1.0,\n",
       " 'ND': 1.0,\n",
       " 'OH': 1.0,\n",
       " 'OK': 1.0,\n",
       " 'OR': 1.0,\n",
       " 'PA': 1.0,\n",
       " 'RI': 1.0,\n",
       " 'SC': 1.0,\n",
       " 'SD': 0.0,\n",
       " 'TN': 0.0,\n",
       " 'TX': 0.0,\n",
       " 'UT': 0.0,\n",
       " 'VT': 1.0,\n",
       " 'VA': 1.0,\n",
       " 'WA': 1.0,\n",
       " 'WV': 1.0,\n",
       " 'WI': 1.0,\n",
       " 'WY': 1.0,\n",
       " nan: nan}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t=pd.read_csv('../../Data for Tax Equity Project/policies/rps.csv')\n",
    "t.rename(columns={'Postal Code':'state', 'Net metering': 'net_meter'},inplace=True)\n",
    "t.set_index('state',inplace=True)\n",
    "t = t['net_meter'].to_dict()\n",
    "with open(jsonDir + 'net_meter.txt', 'w') as outFile:\n",
    "    json.dump(t, outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
